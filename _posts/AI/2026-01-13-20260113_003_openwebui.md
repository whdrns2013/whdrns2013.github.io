---
title: "[Open WebUI] Open WebUI 소개" # 제목 (필수)
excerpt: "로컬과 외부 LLM을 하나의 웹 인터페이스로 사용하는 방법" # 서브 타이틀이자 meta description (필수)
date: 2026-01-13 00:55:00 +0900      # 작성일 (필수)
lastmod: 2026-01-13 00:55:00 +0900   # 최종 수정일 (필수)
last_modified_at: 2026-01-13 00:55:00 +0900   # 최종 수정일 (필수)
categories: AI         # 다수 카테고리에 포함 가능 (필수)
tags: OpenWebUI 로컬 LLM local ollama gui mcp                     # 태그 복수개 가능 (필수)
classes: wide        # wide : 넓은 레이아웃 / 빈칸 : 기본 //// wide 시에는 sticky toc 불가
toc: true        # 목차 표시 여부
toc_label:       # toc 제목
toc_sticky: true # 이동하는 목차 표시 여부 (toc:true 필요) // wide 시에는 sticky toc 불가
header: 
  image:         # 헤더 이미지 (asset내 혹은 url)
  teaser:        # 티저 이미지??
  overlay_image: /assets/images/banners/banner.gif            # 헤더 이미지 (제목과 겹치게)
  # overlay_color: '#333'            # 헤더 배경색 (제목과 겹치게) #333 : 짙은 회색 (필수)
  video:
    id:                      # 영상 ID (URL 뒷부분)
    provider:                # youtube, vimeo 등
sitemap :                    # 구글 크롤링
  changefreq : daily         # 구글 크롤링
  priority : 1.0             # 구글 크롤링
author: # 주인 외 작성자 표기 필요시
permalink: 
sidebar:
  nav: docs_llm
pinned: 
---
<!--postNo: 20260113_003-->

## Intro

![](/assets/images/20260113_003_001.png)  

최근 보안이나 비용 문제로 내 컴퓨터에 직접 LLM 을 돌리는 “로컬 LLM” 에 대한 관심도가 높습니다. 하지만 검은색 터미널 창에서 직접 LLM을 구동시키고, 명령어로 질의를 이어나가는 것은 매우 번거로운 일입니다. 이런 불편함을 해결해줄 수 있는 확장성 높은 LLM GUI 환경이 바로 Open WebUI 입니다.

> ![](/assets/images/20260113_003_002.png)  
> 이런 터미널 창에서만 대화가 가능하다면 너무 불편할 것이다.  

## Open WebUI

![](/assets/images/20260113_003_003.png)  

> Open WebUI is an extensible, feature-rich, and user-friendly self-hosted AI platform designed to operate (entirely) offline. It supports various LLM runners like Ollama and OpenAI-compatible APIs, with built-in inference engine for RAG, making it a powerful AI deployment solution.

Open WebUI(구 Ollama WebUI)는 Ollama와 같은 **로컬 LLM 또는 OpenAI 호환 외부 LLM API를 웹 브라우저에서 ChatGPT 처럼 편리하게 사용할 수 있게 해주는 그래픽 유저 인터페이스**입니다. 확장성이 높고 기능이 풍부하여, 단순한 채팅창을 넘어 강력한 관리 기능을 제공하며, MCP 툴과 같은 외부 도구를 붙이고 커스터마이징 할 수 있습니다. 그리고, 오픈소스 프로젝트라는 점이 큰 장점 중 하나입니다.

> 개인적으로는, 모델·도구·워크플로우를 유연하게 확장할 수 있다는 점에서 단순한 UI 가 아니라 "플랫폼"이라고 생각합니다.  

※ 로컬 LLM 기준으로는 완전 오프라인 구성이 가능하며, 필요에 따라 OpenAI 호환 외부 API도 함께 사용할 수 있습니다.  

## 특징

- **익숙한 UI**: ChatGPT와 거의 흡사한 디자인으로 누구나 쉽게 적응할 수 있다.  
- **로컬 환경**: (설정에 따라)데이터가 외부 서버로 전송되지 않는다.  
- **멀티 모델 지원**: Llama 3, Gemma, Mistral 등 여러 모델을 지원한다.  
- **MCP 지원** : MCP를 지원하므로, 커스텀 툴을 붙일 수 있다.  

### 이런 분들이 써보시면 좋다.

1. **외부로 정보가 반출되는 게 꺼려지는 분**  
2. API 비용 걱정 없이 로컬 LLM을 ChatGPT처럼 사용하고 싶은 분  
3. **나만의 커스텀 LLM 서비스를 만들고 싶으신 분**  

### Outro

- Open WebUI는 단순한 GUI를 넘어, 커스텀 LLM 서비스를 구축할 수 있는 플랫폼입니다.  
- 설치도 간편하고, 설정도 쉬우니 가볍게 시도해보기 좋습니다.  
- 기성 LLM API 도 연결이 가능하므로, 로컬 LLM을 동작시킬 환경이 되지 않아도 사용할 수 있습니다.  

## Reference

[https://github.com/open-webui/open-webui](https://github.com/open-webui/open-webui)  