---
title: "[Pandas] Best Practice - merge 를 통한 해시 기반 조인으로 Python-level 반복문 대체" # 제목 (필수)
excerpt: "Python-level 반복문을 C/CPython-level 반복문으로 바꾸기" # 서브 타이틀이자 meta description (필수)
date: 2025-12-17 07:40:00 +0900      # 작성일 (필수)
lastmod: 2025-12-17 07:40:00 +0900   # 최종 수정일 (필수)
last_modified_at: 2025-12-17 07:40:00 +0900   # 최종 수정일 (필수)
categories: Python          # 다수 카테고리에 포함 가능 (필수)
tags: typography 파이썬 pandas 판다스 성능 향상 감소 best practice for loop 반복문 merge 머지 join 조인 해시 hash c-level cpython cpython-level                # 태그 복수개 가능 (필수)
classes: wide        # wide : 넓은 레이아웃 / 빈칸 : 기본 //// wide 시에는 sticky toc 불가
toc: true        # 목차 표시 여부
toc_label:       # toc 제목
toc_sticky: true # 이동하는 목차 표시 여부 (toc:true 필요) // wide 시에는 sticky toc 불가
header: 
  image:         # 헤더 이미지 (asset내 혹은 url)
  teaser:        # 티저 이미지??
  overlay_image: /assets/images/banners/banner.gif            # 헤더 이미지 (제목과 겹치게)
  # overlay_color: '#333'            # 헤더 배경색 (제목과 겹치게) #333 : 짙은 회색 (필수)
  video:
    id:                      # 영상 ID (URL 뒷부분)
    provider:                # youtube, vimeo 등
sitemap :                    # 구글 크롤링
  changefreq : daily         # 구글 크롤링
  priority : 1.0             # 구글 크롤링
author: # 주인 외 작성자 표기 필요시
permalink: 
sidebar:
  nav: docs_python
---
<!--postNo: 20251217_003-->

## hash 기반 join을 통한 성능 향상  

### Intro  

이전 포스팅들에서 반복 횟수 감소, 딕셔너리 캐싱 방법을 이용해 프로그램의 실행 속도를 개선해봤다. 이번 포스팅에서는, 이전 두 포스팅과 동일한 Dataframe 반복 문제에서 가장 효율적인 실행속도를 보여줄 수 있는 방법을 탐색해보도록 한다.  

### 라이브러리  

```python
import pandas as pd
import random
import time
```

### 실험 데이터셋  

- df_a : user_id, some_data 두 컬럼으로 이루어져 있다.  
- df_a의 some_data 는 약 20% 가량이 NaN 값을 가진다.  
- df_b : user_id, alt_data 두 컬럼으로 이루어져 있다.  
- df_a와 df_b의 user_id 집합은 동일하다.  
- df_b 의 alt_data 에는 결측치가 없다.  

```python
qnt = 10000 # 데이터 수
df_a_origin = pd.DataFrame({
    "user_id" : [str(x) for x in range(1, qnt+1)],
    "some_data" : [random.randint(0, qnt) if random.randint(0, qnt) < qnt*4/5 else None
                   for _ in range(qnt)]
})
df_b = pd.DataFrame({
    "user_id" : [str(x) for x in range(1, qnt+1)],
    "alt_data" : [random.randint(0, qnt) for _ in range(qnt)]
})
```

### 실험의 목표  

- df_a 의 NaN 인 some_data 값을 찾아, df_b 의 동일 user_id 의 alt_data 로 대체한다.  

### 대조군  

- 작동 방식 : df_a 의 각 row 를 순회하며 NaN값 여부를 확인하고, alt_data로 대체한다.  

|순서|작동|시간복잡도|
|---|---|---|
|1|df_a의 각 row를 순회하며, some_data가 NaN인지 확인한다.|O(N_a)|
|2|NaN값인 경우, df_b에서 동일한 user_id 에 해당하는 alt_data를 찾는다.|O(N_b)|
|3|row의 some_data 를 찾은 alt_data로 대체한다.|O(1)|

> 전체 시간복잡도 : O(N_a * N_b)  
> 또한 매 반복마다 boolean mask 를 생성하므로 메모리 비용이 발생  

```python
df_a = df_a_origin.copy()
start = time.time()
for i, row in df_a.iterrows(): #-------- (1)
    if pd.isna(row["some_data"]): #----- (1)
        df_a.at[i, "some_data"] = df_b.loc[df_b["user_id"] == row["user_id"], "alt_data"].iloc[0] #----(2)(3)
print(f"time check 1 ::: {time.time() - start}")
```

```bash
time check 1 ::: 0.7818460464477539
```

### 문제 포착  

- python-level의 반복과 df_b에서 user_id 에 해당되는 row를 찾는 lookup 연산은 큰 연산비용을 가진다.    

### 실험군  

- 작동 방식 : 

|순서|작동|시간복잡도|
|---|---|---|
|1|df_a 와 df_b를 user_id 키를 기준으로 merge한다.|O(N_a + N_b)|
|2|fillna() 메서드를 통해 some_data 가 NaN 인 경우, alt_data로 대체한다.|O(N_a * 1)|

> 전체 시간복잡도 : O(N_a + N_b) + O(N_ * 1)  
> = O(N_a + N_b)  

```python
df_a = df_a_origin.copy()
start = time.time()
df_merge = df_a.merge(df_b, on="user_id", how="left") # O(N_a) + O(N_b)
df_merge["some_data"] = df_merge["some_data"].fillna(df_merge["alt_data"]) # fillna : 벡터화된 연산. O(N_a)
df_merge
print(f"time check 2 ::: {time.time() - start}")
```

```bash
time check 2 ::: 0.00737309455871582
```

### 결과 리뷰  



### 원리  



### 참고 - boolean mask  



